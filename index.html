<!DOCTYPE html>
<html>
<head>
    <title>Facial Landmarks Detection with Incentive Drivers</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
</head>
<body>
    <div style="display: flex; align-items: flex-start;">
        <div style="flex: 1; padding: 20px;">
            <h1>Incentive Drivers for Boxing Events</h1>
            <ul>
                <li>Pay-Per-View Revenue</li>
                <li>Sponsorship Deals</li>
                <li>Ticket Sales</li>
                <li>High-Profile Matchups</li>
                <li>International Exposure</li>
                <li>Media Coverage</li>
            </ul>
        </div>
        <div style="flex: 2;">
            <h1>Real-time Facial Landmarks Detection</h1>
            <video id="webcam" autoplay playsinline></video>
            <canvas id="canvas" width="640" height="480"></canvas>
        </div>
    </div>

    <script>
        async function setupCamera() {
            const video = document.getElementById('webcam');

            const stream = await navigator.mediaDevices.getUserMedia({ 'video': true });
            video.srcObject = stream;

            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function detectFacialLandmarks() {
            const video = await setupCamera();
            video.play();

            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');

            const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
            const detectorConfig = {
                runtime: 'mediapipe',
                solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh',
            };
            const detector = await faceLandmarksDetection.createDetector(model, detectorConfig);

            async function renderPrediction() {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                const faces = await detector.estimateFaces({input: video});

                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                faces.forEach(face => {
                    const keypoints = face.scaledMesh;

                    for (let i = 0; i < keypoints.length; i++) {
                        const [x, y] = keypoints[i];
                        ctx.fillStyle = '#FF0000';
                        ctx.fillRect(x, y, 2, 2);
                    }
                });

                requestAnimationFrame(renderPrediction);
            }

            renderPrediction();
        }

        detectFacialLandmarks();
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <title>Boxing Event Incentive Drivers</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_landmarks"></script>
</head>
<body>
    <div style="display: flex; align-items: flex-start;">
        <div style="flex: 1; padding: 20px;">
            <h1>Incentive Drivers for Boxing Events</h1>
            <ul>
                <li>Pay-Per-View Revenue</li>
                <li>Sponsorship Deals</li>
                <li>Ticket Sales</li>
                <li>High-Profile Matchups</li>
                <li>International Exposure</li>
                <li>Media Coverage</li>
            </ul>
        </div>
        <div style="flex: 2;">
            <h1>Real-time Face Detection with Landmarks</h1>
            <video id="webcam" autoplay playsinline></video>
            <canvas id="canvas" width="640" height="480"></canvas>
        </div>
    </div>

    <script>
        async function setupCamera() {
            const video = document.getElementById('webcam');

            const stream = await navigator.mediaDevices.getUserMedia({ 'video': true });
            video.srcObject = stream;

            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function detectFaces() {
            const video = await setupCamera();
            video.play();

            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');

            const faceDetector = new faceDetection.FaceDetector({
                modelUrl: faceDetection.SupportedModels.MediaPipeFaceDetector
            });

            const faceLandmarks = new faceLandmarks.FaceLandmarks({
                modelUrl: faceLandmarks.SupportedModels.MediaPipeFaceLandmark
            });

            async function renderPrediction() {
                const faces = await faceDetector.estimateFaces(video);

                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                faces.forEach(face => {
                    const boundingBox = face.boundingBox;
                    ctx.strokeStyle = '#00FF00';
                    ctx.lineWidth = 2;
                    ctx.strokeRect(boundingBox.x, boundingBox.y, boundingBox.width, boundingBox.height);

                    const landmarks = faceLandmarks.estimateLandmarks(face);

                    landmarks.forEach(landmark => {
                        ctx.fillStyle = '#FF0000';
                        ctx.fillRect(landmark.x, landmark.y, 5, 5);
                    });
                });

                requestAnimationFrame(renderPrediction);
            }

            renderPrediction();
        }

        detectFaces();
    </script>
</body>
</html>
